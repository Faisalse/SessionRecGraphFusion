type: opt # single|window, maybe add opt
key: TuningOfModelsOnTestData_DIGI #added to the csv names
evaluation: evaluation #evaluation|evaluation_last|evaluation_multiple|evaluation_user_based|evaluation_user_based_multiple

data:
  name: diginetica #added in the end of the csv names
  folder: data/diginetica/TuneOnTestData/
  prefix: diginetica
  opts: {sessions_test: 100}

results:
  folder: results/
metrics:
- class: accuracy.MRR
  length: [3,5,10,15,20]
- class: accuracy.HitRate
  length: [3,5,10,15,20]
- class: coverage.Coverage
  length: [20]
- class: popularity.Popularity
  length: [20]
- class: saver.Saver
  length: [50]
- class: time_memory_usage.Time_usage_training
- class: time_memory_usage.Time_usage_testing

optimize:
  class: accuracy.MRR
  length: [20]
  iterations: 30  #optional

algorithms:



- class: TAGNN.TAGNN.TAGNN
  params: { }
  params_opt:
    epoch: [10, 15, 20, 25]
    lr: [{from: 0.01, to: 0.001, in: 10, type: float32},{from: 0.001, to: 0.0001, in: 10, type: float32}]
    batch_size: [20, 32, 100, 128, 200]
    embedding_size: [50, 100, 150]
    l2: [0.00001, 0.0001]
  key: TAGNN

- class: GNRRW.GNRRW.GNRRW
  params: { }
  params_opt:
    epoch: [10, 15, 20, 25]
    lr: [{from: 0.01, to: 0.0001, in: 10, type: float32}]
    batch_size: [20, 32, 100, 128, 200]
    embedding_size: [20, 32, 100, 128, 200]
    l2: [0.00001, 0.0001]
  key: GNRRW

- class: FLCSP.FLCSP_cate.FLCSP_cate
  params: { }
  params_opt:
    epoch: [10, 15, 20, 25]
    lr: [{from: 0.01, to: 0.001, in: 10, type: float32},{from: 0.001, to: 0.0001, in: 10, type: float32}]
    batch_size: [20, 32, 100, 128, 200, 300]
    embedding_size: [20, 32, 100, 128, 200, 300]
    hidden_size: [100, 150, 200, 250, 300]
    dropout: [0.1,0.2,0.3, 0.4, 0.5]
    l2: [0.00001, 0.0001]
  key: FLCSP_cate

- class: sgnn.gnn.GGNN
  params: {  }
  params_opt:
    epoch: [10, 15, 20, 25]
    lr: [0.009]
    embedding_size: [16, 32, 64, 80, 100, 150, 200]
    batch_size: [16, 32, 128, 256, 200]
    l2: [0.0001, 0.00004, 0.00001]
  key: GGNN

- class: COTREC.COTREC.COTRECModel
  params: { }
  params_opt:
   epoch: [10, 15, 20, 25]
   lr: [{from: 0.01, to: 0.001, in: 10, type: float32},{from: 0.001, to: 0.0001, in: 10, type: float32}]
   batch_size: [20, 50, 100]
   embedding_size: [20, 50, 100]
   l2: [0.0001, 0.00001]
  key: COTREC

